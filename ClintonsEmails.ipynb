{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as pd\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    emails = pd.read_csv('./Emails.csv').dropna(subset=['SenderPersonId','ExtractedBodyText','ExtractedSubject'])\n",
    "    emails_receivers = pd.read_csv('EmailReceivers.csv')\n",
    "            \n",
    "    text = [re.sub('[^a-zA-Z0-9]', ' ', bodytext) for bodytext in emails.ExtractedBodyText]\n",
    "    return pd.DataFrame({'sender': list(map(int, emails.SenderPersonId)), \n",
    "                         'subject': emails.ExtractedSubject, 'message': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sender</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thx</td>\n",
       "      <td>32</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pis print             H   hrod17 clintonernail...</td>\n",
       "      <td>80</td>\n",
       "      <td>Meet The Right Wing Extremist Behind Anti-Musl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FYI</td>\n",
       "      <td>87</td>\n",
       "      <td>FVV: Secretary's remarks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fyi B6</td>\n",
       "      <td>87</td>\n",
       "      <td>AbZ and Hb3 on Libya and West Bank/Gaza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>87</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message  sender  \\\n",
       "2                                                 Thx      32   \n",
       "5   Pis print             H   hrod17 clintonernail...      80   \n",
       "8                                                 FYI      87   \n",
       "10                                     Fyi B6              87   \n",
       "12                                                Fyi      87   \n",
       "\n",
       "                                              subject  \n",
       "2                                   Re: Chris Stevens  \n",
       "5   Meet The Right Wing Extremist Behind Anti-Musl...  \n",
       "8                            FVV: Secretary's remarks  \n",
       "10            AbZ and Hb3 on Libya and West Bank/Gaza  \n",
       "12                                                hey  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), min_df=10).fit(df.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'your trip', 3168),\n",
       " (u'your own', 3167),\n",
       " (u'your message', 3166),\n",
       " (u'your help', 3165),\n",
       " (u'your call', 3164),\n",
       " (u'you would', 3163),\n",
       " (u'you will', 3162),\n",
       " (u'you when', 3161),\n",
       " (u'you were', 3160),\n",
       " (u'you we', 3159)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigram_vectorizer.vocabulary_.items(), key=lambda v:-v[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DENNIS', 'ROSS'),\n",
       " ('LUIS', 'AMADO'),\n",
       " ('MARIE', 'SLAUGHTER'),\n",
       " ('NOER', 'HASSAN'),\n",
       " ('Vital', 'Voices'),\n",
       " ('x7', '7203'),\n",
       " ('ANNE', 'MARIE'),\n",
       " ('ARTURO', 'VALENZUELA'),\n",
       " ('BINYAMIN', 'NETANYAHU'),\n",
       " ('Beacon', 'Theater')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.collocations\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "bam = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(word_tokenize(' '.join(df.message)))\n",
    "finder.apply_freq_filter(4)\n",
    "finder.nbest(bam.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = TfidfVectorizer(max_df=1000, min_df=10).fit_transform(df.message).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "CLUSTERS_COUNT = 7\n",
    "\n",
    "predicts = KMeans(n_clusters=CLUSTERS_COUNT, random_state=1).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predicts = df.copy()\n",
    "df_predicts['predicts'] = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sender</th>\n",
       "      <th>subject</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thx</td>\n",
       "      <td>32</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pis print             H   hrod17 clintonernail...</td>\n",
       "      <td>80</td>\n",
       "      <td>Meet The Right Wing Extremist Behind Anti-Musl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FYI</td>\n",
       "      <td>87</td>\n",
       "      <td>FVV: Secretary's remarks</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fyi B6</td>\n",
       "      <td>87</td>\n",
       "      <td>AbZ and Hb3 on Libya and West Bank/Gaza</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>87</td>\n",
       "      <td>hey</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message  sender  \\\n",
       "2                                                 Thx      32   \n",
       "5   Pis print             H   hrod17 clintonernail...      80   \n",
       "8                                                 FYI      87   \n",
       "10                                     Fyi B6              87   \n",
       "12                                                Fyi      87   \n",
       "\n",
       "                                              subject  preds  \n",
       "2                                   Re: Chris Stevens      7  \n",
       "5   Meet The Right Wing Extremist Behind Anti-Musl...      5  \n",
       "8                            FVV: Secretary's remarks      8  \n",
       "10            AbZ and Hb3 on Libya and West Bank/Gaza      8  \n",
       "12                                                hey      8  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(u'zuckerman', 5886), (u'zone', 5885), (u'zia', 5884), (u'zi', 5883), (u'zelaya', 5882)]\n",
      "1 [(u'sigh', 11), (u'paymasters', 10), (u'just', 9), (u'jpg', 8), (u'image003', 7)]\n",
      "2 [(u'yup', 117), (u'yes', 116), (u'yep', 115), (u'xo', 114), (u'works', 113)]\n",
      "3 [(u'zzity', 20609), (u'zx', 20608), (u'zwire', 20607), (u'zurich', 20606), (u'zumbi', 20605)]\n",
      "4 [(u'vu', 60), (u'version', 59), (u'thx', 58), (u'speech', 57), (u'review', 56)]\n",
      "5 [(u'zimbabwean', 2642), (u'zia', 2641), (u'zebari', 2640), (u'zatlers', 2639), (u'yukiya', 2638)]\n",
      "6 [(u'yes', 25), (u'work', 24), (u'waldorf', 23), (u'thx', 22), (u'talk', 21)]\n"
     ]
    }
   ],
   "source": [
    "for cluster in xrange(CLUSTERS_COUNT):\n",
    "    cv = CountVectorizer(stop_words='english').fit(df_predicts[df_predicts.predicts == cluster].message)\n",
    "    word_counts = sorted(cv.vocabulary_.items(), key=lambda v:-v[1])[:5]\n",
    "    print cluster, word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(u'zuckerman', 2373), (u'zest', 2372), (u'zelaya', 2371), (u'zebari', 2370), (u'zak', 2369)]\n",
      "1 [(u'zelikow', 970), (u'zelaya', 969), (u'zardari', 968), (u'young', 967), (u'yohannes', 966)]\n",
      "2 [(u'young', 208), (u'wrong', 207), (u'work', 206), (u'wilson', 205), (u'weekend', 204)]\n",
      "3 [(u'zelaya', 1492), (u'zebari', 1491), (u'zardari', 1490), (u'zach', 1489), (u'youtube', 1488)]\n",
      "4 [(u'zones', 282), (u'york', 281), (u'women', 280), (u'week', 279), (u'ways', 278)]\n",
      "5 [(u'zebari', 566), (u'zealand', 565), (u'yohannes', 564), (u'yellow', 563), (u'yang', 562)]\n",
      "6 [(u'zones', 262), (u'yohannes', 261), (u'workers', 260), (u'work', 259), (u'word', 258)]\n"
     ]
    }
   ],
   "source": [
    "for cluster in xrange(CLUSTERS_COUNT):\n",
    "    cv = CountVectorizer(stop_words='english').fit(df_predicts[df_predicts.predicts == cluster].subject)\n",
    "    word_counts = sorted(cv.vocabulary_.items(), key=lambda v:-v[1])[:5]\n",
    "    print cluster, word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По поводу способа интерпретировать результаты:\n",
    "Посадить ассессора и для каждого слова из небольшой случайной подвыборки кластера отвечать на вопросы: \n",
    "* принадлежит ли слово оставшейся части кластера (на его взгляд)\n",
    "* отличается ли слово от остальных кластеров\n",
    "\n",
    "И можно строить аналоги precision и recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
